{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Metricas\n",
    "---\n",
    "\n",
    "- **Taller 3**: Pipe-line de entrenamiento.\n",
    "- **Fecha de entrega**: 7 de Junio de 2023.\n"
   ],
   "metadata": {
    "id": "OSQGVvroGMC-"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T23:39:00.298189Z",
     "start_time": "2024-06-04T23:38:56.650558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "En esta ocasión crearán un calificador capas de identificar si una palabra pertenece al lenguaje inglés o español."
   ],
   "metadata": {
    "id": "mC06A62ypZQ4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#0. Cargue el conjunto de datos\n",
    "\n",
    "Inicialmente, necesitará un corpus correspondiente a ambos idiomas, descárguelos (español: https://github.com/webpwnized/byepass/blob/master/dictionaries/top-10000-spanish-words.txt, inglés: https://github.com/webpwnized/byepass/blob/master/dictionaries/top-10000-english-words.txt)\n",
    "\n",
    "Considere únicamente las palabras mayores a 4 caracteres e ignore cualquier acento"
   ],
   "metadata": {
    "id": "VZ-Qr2GhJVNC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open('top-10000-spanish-words.txt', 'r', encoding='utf-8') as f:\n",
    "    palabras_espanol = f.read().splitlines()\n",
    "    palabras_espanol = [palabra for palabra in palabras_espanol if len(palabra) >= 4]\n",
    "with open('top-10000-english-words.txt', 'r', encoding='utf-8') as f:\n",
    "    palabras_ingles = f.read().splitlines()\n",
    "    palabras_ingles = [palabra for palabra in palabras_ingles if len(palabra) >= 4]\n",
    "etiquetas_espanol = ['espanol'] * len(palabras_espanol)\n",
    "etiquetas_ingles = ['ingles'] * len(palabras_ingles)\n",
    "data = pd.DataFrame({\n",
    "    'palabra': palabras_espanol + palabras_ingles,\n",
    "    'etiqueta': etiquetas_espanol + etiquetas_ingles\n",
    "})\n",
    "print(data)"
   ],
   "metadata": {
    "id": "JbGllmjhJ4zZ",
    "ExecuteTime": {
     "end_time": "2024-06-04T22:34:47.613442Z",
     "start_time": "2024-06-04T22:34:47.472209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         palabra etiqueta\n",
      "0          añade  espanol\n",
      "1        añadido  espanol\n",
      "2         añadio  espanol\n",
      "3         añadir  espanol\n",
      "4          abajo  espanol\n",
      "...          ...      ...\n",
      "17175      zones   ingles\n",
      "17176     zoning   ingles\n",
      "17177  zoophilia   ingles\n",
      "17178       zope   ingles\n",
      "17179     zshops   ingles\n",
      "\n",
      "[17180 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T23:31:54.361785Z",
     "start_time": "2024-06-04T23:31:54.325809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_accents(word):\n",
    "    no_accents = unicodedata.normalize('NFD', word)\n",
    "    no_accents = no_accents.encode('ascii', 'ignore').decode('ascii')\n",
    "    no_accents = unicodedata.normalize('NFC', no_accents)\n",
    "    return no_accents"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T23:32:03.501472Z",
     "start_time": "2024-06-04T23:32:03.451800Z"
    }
   },
   "cell_type": "code",
   "source": "data['palabra'] = data['palabra'].apply(remove_accents)",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T23:32:10.904971Z",
     "start_time": "2024-06-04T23:32:10.845560Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         palabra etiqueta\n",
       "0          anade  espanol\n",
       "1        anadido  espanol\n",
       "2         anadio  espanol\n",
       "3         anadir  espanol\n",
       "4          abajo  espanol\n",
       "...          ...      ...\n",
       "17175      zones   ingles\n",
       "17176     zoning   ingles\n",
       "17177  zoophilia   ingles\n",
       "17178       zope   ingles\n",
       "17179     zshops   ingles\n",
       "\n",
       "[17180 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra</th>\n",
       "      <th>etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anade</td>\n",
       "      <td>espanol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anadido</td>\n",
       "      <td>espanol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anadio</td>\n",
       "      <td>espanol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anadir</td>\n",
       "      <td>espanol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abajo</td>\n",
       "      <td>espanol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17175</th>\n",
       "      <td>zones</td>\n",
       "      <td>ingles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17176</th>\n",
       "      <td>zoning</td>\n",
       "      <td>ingles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17177</th>\n",
       "      <td>zoophilia</td>\n",
       "      <td>ingles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17178</th>\n",
       "      <td>zope</td>\n",
       "      <td>ingles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17179</th>\n",
       "      <td>zshops</td>\n",
       "      <td>ingles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17180 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T23:40:32.171165Z",
     "start_time": "2024-06-04T23:40:31.910979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vectorizar las palabras\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['palabra'])\n",
    "\n",
    "# Convertir las etiquetas a un formato adecuado\n",
    "y = data['etiqueta']"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T23:40:59.099353Z",
     "start_time": "2024-06-04T23:40:54.771650Z"
    }
   },
   "cell_type": "code",
   "source": "print(X)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 748)\t1.0\n",
      "  (1, 749)\t1.0\n",
      "  (2, 750)\t1.0\n",
      "  (3, 751)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 2)\t1.0\n",
      "  (6, 3)\t1.0\n",
      "  (7, 4)\t1.0\n",
      "  (8, 5)\t1.0\n",
      "  (9, 7)\t1.0\n",
      "  (10, 8)\t1.0\n",
      "  (11, 9)\t1.0\n",
      "  (12, 10)\t1.0\n",
      "  (13, 11)\t1.0\n",
      "  (14, 12)\t1.0\n",
      "  (15, 14)\t1.0\n",
      "  (16, 15)\t1.0\n",
      "  (17, 16)\t1.0\n",
      "  (18, 17)\t1.0\n",
      "  (19, 18)\t1.0\n",
      "  (20, 21)\t1.0\n",
      "  (21, 22)\t1.0\n",
      "  (22, 23)\t1.0\n",
      "  (23, 24)\t1.0\n",
      "  (24, 27)\t1.0\n",
      "  :\t:\n",
      "  (17155, 17041)\t1.0\n",
      "  (17156, 17042)\t1.0\n",
      "  (17157, 17043)\t1.0\n",
      "  (17158, 17044)\t1.0\n",
      "  (17159, 17045)\t1.0\n",
      "  (17160, 17046)\t1.0\n",
      "  (17161, 17047)\t1.0\n",
      "  (17162, 17048)\t1.0\n",
      "  (17163, 17049)\t1.0\n",
      "  (17164, 17050)\t1.0\n",
      "  (17165, 17052)\t1.0\n",
      "  (17166, 17053)\t1.0\n",
      "  (17167, 17054)\t1.0\n",
      "  (17168, 17060)\t1.0\n",
      "  (17169, 17061)\t1.0\n",
      "  (17170, 17063)\t1.0\n",
      "  (17171, 17064)\t1.0\n",
      "  (17172, 17065)\t1.0\n",
      "  (17173, 17066)\t1.0\n",
      "  (17174, 17069)\t1.0\n",
      "  (17175, 17070)\t1.0\n",
      "  (17176, 17071)\t1.0\n",
      "  (17177, 17072)\t1.0\n",
      "  (17178, 17073)\t1.0\n",
      "  (17179, 17074)\t1.0\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Propongan un experimento (0.5)\n",
    "\n",
    "¡Señale de forma ESCRITA!, las partes de su experimento y como plantea desarrollarlas.\n",
    "\n",
    "**WARINING**\n",
    "\n",
    "Por favor no tome a la ligera el punto, sea detallado y cuidadoso con su propuesta, pues sí elige mal el desarrollo de su experimento, su nota en el resto de puntos se vera afectada!!!\n",
    "\n",
    "\n",
    "**Criterios de evolución**\n",
    "\n",
    "*   Si su respuesta no está escrita, este punto equivaldrá a 0\n",
    "*   Debe realizar las exploraciones necesarias que le permita obtener la información suficiente para identificar un diseño experimental correcto (ej: balance de clases, etc...).\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "UuuPFkUdPWRt"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "On8gYlZ6q3C0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#2. Precalcule diferentes matrices de kernel (0.5)\n",
    "\n",
    "Implemente diferentes kernels sobre los strings:\n",
    "\n",
    "*   Kernel coseno sobre el histograma: calcular una bolsa de representación de n-gramas (usar el CountVectorizer de scikit-learn) y aplicar el cosine_similarity (consulte: https://keepcoding.io/blog/similitud-entre-vectores-o-cosine-similarity/)\n",
    "\n",
    "*    Minima intersección de histograma: calcular una bolsa de n-gramas de representación, normalizarlo  y calcular la suma de los mínimos de cada bin del histograma (https://mpatacchiola.github.io/blog/2016/11/12/the-simplest-classifier-histogram-intersection.html).\n",
    "\n",
    "*   kernel χ2 : calcular una representación de bolsa de n-gramas y aplicar el chi2_kernel de scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.chi2_kernel.html).\n",
    "\n",
    "\n",
    "**FAQ**\n",
    "\n",
    "*   ¿Por qué este kernel?, recuerde que el kernel está estrechamente asociado a la naturaleza de los datos.\n",
    "*   ¿No entiendo el kernel de intersección?, en pocas palabras, imagine una matriz (tamaño 2,n). Donde cada fila corresponde al histograma de una observación. Calcule el mínimo entre filas, resultando un vector n posiciones, seguidamente sumelo!\n",
    "\n",
    "**Criterios de evolución**\n",
    "\n",
    "*   La función diseñada de permitir el cálculo EFICIENTE de la matriz de gram.\n",
    "\n"
   ],
   "metadata": {
    "id": "pMxTgtEfRRmY"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "NCEIqeCLuZ7k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#3. Identifique hiperparametros (1)\n",
    "\n",
    "Utilice scikit-learn para entrenar diferentes SVMs utilizando kernels precalculados. Utilice la validación cruzada para encontrar los parámetros de regularización apropiados trazando el error de entrenamiento y validación frente al parámetro de regularización. Utilice una escala logarítmica para C {1e-5,1e-4,1e-3,1e-2, 1e-1, 1}, Pruebe diferentes configuraciones de los parámetros (en particular, diferentes valores de n para la\n",
    "n-gramas).\n",
    "\n",
    "**FAQ**\n",
    "\n",
    "*   ¿Qué es una escala logarítmica?, como puede ver en el ejemplo, es una escala que se mueve a través de su potencia.\n",
    "*   ¿profe, por qué tarda tanto?, se los advertí ._________.\n",
    "\n",
    "**Criterios de evolución**\n",
    "\n",
    "*   Debe presentar la exploración de hiperparámetros completa y las gráficas del desempeño del modelo, respecto a la variación del parámetro C (en total debe salir una gráfica por cada combinación de kernel y grado de n-grama)."
   ],
   "metadata": {
    "id": "wp4bppOlWjHs"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "izx4-grjXUu-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#4. Evalue su modelo (0.5)\n",
    "\n",
    "*   Presente los resultados en una tabla para las distintas configuraciones evaluadas.\n",
    "\n",
    "*  Ilustre ejemplos de errores (palabras en inglés confundidas con español, palabras en español\n",
    "inglés). Dé una posible explicación de estos errores.\n",
    "\n",
    "\n",
    "* Discuta los resultados."
   ],
   "metadata": {
    "id": "27liX4P7wxDa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "introduzca su respuesta"
   ],
   "metadata": {
    "id": "mhwXHTAUxUzV"
   }
  }
 ]
}
